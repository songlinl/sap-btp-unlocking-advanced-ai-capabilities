{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n",
    "  <img src=\"./images/btp-banner.gif\" alt=\"SAP HANA Cloud\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval-Augmented Generation with SAP HANA Cloud Vector Engine\n",
    "\n",
    "In this demo, we will explore how to enhance the capabilities of Large Language Models (LLMs) with **SAP HANA Cloud vector engine**. You will learn how to embed unstructured and semi-structured data data using LLMs from **SAP Generative AI Hub**, store the vecotr embeddings in **SAP HANA Cloud**. Additionally, you will query vector embeddings, and forward the relevant results to a LLM for a augmented answer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØLearning Objectives\n",
    "By the end of this demo, you will be able to:\n",
    "- Implement a full RAG pipeline using Python, LangChain, and Generative AI Hub SDK.\n",
    "- Generate embeddings for document chunks using Generative AI Hub SDK.\n",
    "- Retrieve the most relevant content based on semantic similarity using SAP HANA Cloud similarity search.\n",
    "- Augment user prompts with retrieved context and invoke LLMs (e.g., GPT-4o) to generate more accurate, grounded answers.\n",
    "- Design and use prompt templates to enhance the quality of generated responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üö®Requirements\n",
    "\n",
    "Please review the following requirements before starting the demo: \n",
    "- Enable the additional feature **Natrual Language Processing (NPL)** in your SAP HANA Cloud database \n",
    "- Deploy Large Language Models (LLMs): **text-embedding-ada-002** and **gpt-4o** in SAP AI Launchpad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìùAbout the Data\n",
    "\n",
    "The data set is a product catalog of IT accessory products. Here are the main attributes and their descriptions based on the sample data:\n",
    "\n",
    "|Field          |Description            |\n",
    "----------------|-----------------------\n",
    "|**PRODUCT_ID**| A unique identifier for each product.|\n",
    "|**PRODUCT_NAME**| The name of the product, which typically includes the brand and the model.|\n",
    "|**CATEGORY**| The general category of the product, which is \"IT Accessories\" for all entries sampled.|\n",
    "|**DESCRIPTION**| A detailed description of the product, highlighting key features and specifications.|\n",
    "|**UNIT_PRICE**| The price of the product in Euros.|\n",
    "|**UNIT_MEASURE**| The unit of measure for the product, typically \"Each\" indicating pricing per item.|\n",
    "|**SUPPLIER_ID**| A unique identifier for the supplier of the product.|\n",
    "|**SUPPLIER_NAME**| The name of the supplier.|\n",
    "|**LEAD_TIME_DAYS**| The number of days it takes from order to delivery.|\n",
    "|**MIN_ORDER**| The minimum order quantity required.|\n",
    "|**CURRENCY**| The currency of the transaction, which is \"EURO\" for all entries.|\n",
    "|**SUPPLIER_COUNTRY**| The country where the supplier is located, which is \"Germany\" for all sampled entries.|\n",
    "|**SUPPLIER_ADDRESS**| The physical address of the supplier.|\n",
    "|**AVAILABILITY_DAYS**| The number of days the product is available for delivery.|\n",
    "|**SUPPLIER_CITY**| The city where the supplier is located.|\n",
    "|**STOCK_QUANTITY**| The quantity of the product currently in stock.|\n",
    "|**MANUFACTURER**| The company that manufactured the product.|\n",
    "|**CITY_LAT**| Geographical coordinates of the city (latitude)|\n",
    "|**CITY_LONG**| Geographical coordinates of the city (longitude).|\n",
    "|**RATING:**| A rating for the product, which are on a scale from 1 to 5.|\n",
    "\n",
    "</br>\n",
    "\n",
    "This dataset is structured to support various business operations such as inventory management, order processing, and logistics planning, providing a comprehensive view of product offerings, supplier details, and stock levels. Each entry is highly detailed, suggesting the dataset could be used for analytical purposes, such as optimizing supply chain operations or analyzing sales and marketing strategies.\n",
    "\n",
    "</br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Install Python packages\n",
    "\n",
    "Run the following package installations. **pip** is the package installer for Python. You can use pip to install packages from the Python Package Index and other indexes.\n",
    "\n",
    "**Note:** Jupyter Notebook kernel restart required after package installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install hdbcli --break-system-packages\n",
    "%pip install generative-ai-hub-sdk[all] --break-system-packages\n",
    "%pip install langchain-hana --break-system-packages\n",
    "%pip install folium --break-system-packages\n",
    "%pip install ipywidgets --break-system-packages\n",
    "%pip install python-dotenv --break-system-packages\n",
    "\n",
    "# kernel restart required!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ö†Ô∏èThe Python kernel needs to be restarted before continuing. \n",
    "\n",
    "> ![](./images/config_001.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Configure AI Core Client\n",
    "Execute the configuration module below to enable access to SAP Generative AI foundation models. This configuration is automatically done by running configuration module in the code block.\n",
    "\n",
    "> You could also set up the same by running a terminal command:\n",
    ">```bash\n",
    ">aicore configure\n",
    ">```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generative AI Config\n",
    "from ai_core_sdk.ai_core_v2_client import AICoreV2Client\n",
    "from gen_ai_hub.proxy.gen_ai_hub_proxy import GenAIHubProxyClient\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # take environment variables from .env.\n",
    "\n",
    "# Get the AI Core URL from environment variables\n",
    "URL = os.getenv('AICORE_AUTH_URL')\n",
    "# Get the AI Core client ID from environment variables\n",
    "CLIENT_ID = os.getenv('AICORE_CLIENT_ID')\n",
    "# Get the AI Core client secret from environment variables\n",
    "CLIENT_SECRET = os.getenv('AICORE_CLIENT_SECRET')\n",
    "# Get the AI Core client ID from environment variables\n",
    "RESOURCE_GROUP = os.getenv('AICORE_RESOURCE_GROUP')\n",
    "# Get the AI Core client secret from environment variables\n",
    "API_URL = os.getenv('AICORE_BASE_URL')\n",
    "\n",
    "# Set up the AICoreV2Client\n",
    "ai_core_client = AICoreV2Client(base_url=API_URL,\n",
    "                            auth_url=URL,\n",
    "                            client_id=CLIENT_ID,\n",
    "                            client_secret=CLIENT_SECRET,\n",
    "                            resource_group=RESOURCE_GROUP)\n",
    "\n",
    "# Initialize GenAIHub proxy client\n",
    "proxy_client = GenAIHubProxyClient(ai_core_client=ai_core_client)\n",
    "print(\"‚úÖAI Core Client connection is established successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the test below to test SAP AI Core configuration by making a call to the **text-embedding-ada-002** model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test embeddings\n",
    "\n",
    "from gen_ai_hub.proxy.native.openai import embeddings\n",
    "\n",
    "response = embeddings.create(\n",
    "    input=\"SAP Generative AI Hub is awesome!\",\n",
    "    model_name=\"text-embedding-ada-002\"\n",
    "    \n",
    ")\n",
    "print(response.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the embeddings model **text-embedding-ada-002**. This model will be used to generate embeddings for both documents and the user's prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize embeddings\n",
    "\n",
    "from gen_ai_hub.proxy.langchain import OpenAIEmbeddings\n",
    "open_ai_embedding_model = OpenAIEmbeddings(proxy_model_name='text-embedding-ada-002', chunk_size=100, max_retries=10)\n",
    "print(\"‚úÖEmbedding model 'text-embedding-ada-002' is initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the LLM model **gpt-4o**. This model is used for generating responses or interacting in a chat-like environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM\n",
    "\n",
    "from gen_ai_hub.proxy.langchain import ChatOpenAI\n",
    "llm = ChatOpenAI(proxy_model_name='gpt-4o', proxy_client=proxy_client)\n",
    "print(\"‚úÖLLM model 'gpt-4o' is initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Ask LLM without business context\n",
    "\n",
    "After completing the configuration we are ready to ask the first question directly to LLM (gpt-4o) without any business product context to find us products with a rating of 4 and more. The response is arbitrary and does not relate to our product data. \n",
    "\n",
    ">**Note**: If we directly pass the prompt to the model without RAG, this will be the output. Later, we can compare how the output produced by RAG is different from this output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "question = \"Suggest a keyboard with a rating 4 or more\"\n",
    "llm.temperature=0.7\n",
    "response = llm.invoke(question)\n",
    "display(Markdown(response.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Prepare the documentation\n",
    "\n",
    "This code snippet demonstrates how to load and process text data from a CSV file using the `CSVLoader` from the `langchain.document_loaders.csv_loader` module.\n",
    "\n",
    "This process is useful for handling large text data, making it more manageable or suitable for further processing, analysis, or input into machine learning models, especially when dealing with limitations on input size.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process CSV data file\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "loader = CSVLoader(\n",
    "    file_path=\"data/new_product.csv\",\n",
    "    encoding=\"utf-8\",\n",
    "    csv_args={\n",
    "        \"delimiter\": \";\",\n",
    "        \"quotechar\": '\"'\n",
    "    },\n",
    ")\n",
    "\n",
    "# Process data\n",
    "\n",
    "text_documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "text_chunks = text_splitter.split_documents(text_documents)\n",
    "print(f\"Number of document chunks: {len(text_chunks)}\")\n",
    "# print(text_chunks)\n",
    "\n",
    "for chunks in text_chunks:\n",
    "    print(chunks.metadata)\n",
    "    print(chunks.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Connect to SAP HANA Cloud Database\n",
    "\n",
    "The provided Python script imports database connection modules and initiates a connection to a SAP HANA Cloud instance using the `dbapi` module. The user is prompted to enter their username and password, which are then used to establish a secure connection to the SAP HANA Cloud database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HC Vector Engine\n",
    "from hdbcli import dbapi\n",
    "\n",
    "# Get the HANA Cloud username from environment variables\n",
    "HANA_USER = os.getenv('HANA_VECTOR_USER')\n",
    "# Get the HANA Cloud password from environment variables\n",
    "HANA_PASS = os.getenv('HANA_VECTOR_PASS')\n",
    "# Get the HANA Cloud host from environment variables\n",
    "HANA_HOST = os.getenv('HANA_VECTOR_HOST')\n",
    "\n",
    "# Establish a connection to the HANA Cloud database using HANA_ML package\n",
    "connection = dbapi.connect(\n",
    "    address=HANA_HOST,\n",
    "    port=443,\n",
    "    user=HANA_USER,\n",
    "    password=HANA_PASS,\n",
    "    autocommit=True,\n",
    "    sslValidateCertificate=False,\n",
    ")\n",
    "print(\"‚úÖHANA Cloud connection is established successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Create a LangChain VectorStore interface to store the embeddings\n",
    "\n",
    "The `langchain_community.vectorstores.hanavector` library, specifically the `HanaDB` class, from the LangChain community, is designed to interact with vector data stored in SAP HANA Cloud database, and enables developers to utilize SAP HANA Cloud's advanced capabilities for managing and querying vector data, in the context of AI and machine learning applications.\n",
    "\n",
    "This cell will create a LangChain VectorStore interface for the HANA database and specify the table (collection) to use for accessing the vector embeddings. Embeddings are vector representations of text data that incorporate the semantic meaning of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_hana import HanaDB\n",
    "\n",
    "#Create a LangChain VectorStore interface for the HANA database and specify the table (collection) to use for accessing the vector embeddings\n",
    "vector_table = HanaDB(\n",
    "    embedding=open_ai_embedding_model, \n",
    "    connection=connection, \n",
    "    table_name=\"PRODUCTS_IT_ACCESSORY_ADA_\"+ HANA_USER,\n",
    "    content_column=\"VEC_TEXT\", # the original text description of the product details\n",
    "    metadata_column=\"VEC_META\", # metadata associated with the product details\n",
    "    vector_column=\"VEC_VECTOR\" # the vector representation of each product \n",
    ")\n",
    "\n",
    "print(\"‚úÖVector Database connection is established successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete already existing documents from the table\n",
    "vector_table.delete(filter={})\n",
    "\n",
    "# add the loaded document chunks\n",
    "vector_table.add_documents(text_chunks)\n",
    "print(\"‚úÖThe vector table is created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the table to verify embeddings\n",
    "cursor = connection.cursor()\n",
    "sql = f'SELECT VEC_TEXT, TO_NVARCHAR(VEC_VECTOR) FROM \"{vector_table.table_name}\"'\n",
    "\n",
    "cursor.execute(sql)\n",
    "vectors = cursor.fetchall()\n",
    "\n",
    "for vector in vectors:\n",
    "    print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Define a prompt template to provide business context\n",
    "\n",
    "Define a prompt template to provide context to our prompts. Thus, when passed to the model, the template will add the necessary context to the prompt so that more accurate results are generated.\n",
    "\n",
    "The answer should contain the requested information about products and their descriptions, formatted according to the specified JSON structure for further use in the SAP HANA JSON Document store.\n",
    "\n",
    "> **Note**: The created template for the prompt contains two variables - **context** and **question**. These variables will be replaced with the context and question in the upcoming steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "prompt_template = \"\"\"use the following pieces of context to answer the question at the end. If you don't know the answer,\n",
    "    just say you don't know, don't try to make up an answer. Format the results in a list of JSON items with the following keys:\n",
    "\n",
    "        \"PRODUCT_ID\", \n",
    "        \"PRODUCT_NAME\",\n",
    "        \"CATEGORY\",\n",
    "        \"DESCRIPTION\",\n",
    "        \"UNIT_PRICE\",\n",
    "        \"UNIT_MEASURE\",\n",
    "        \"SUPPLIER_ID\",\n",
    "        \"SUPPLIER_NAME\",\n",
    "        \"LEAD_TIME_DAYS\",\n",
    "        \"MIN_ORDER\",\n",
    "        \"CURRENCY\",\n",
    "        \"SUPPLIER_COUNTRY\",\n",
    "        \"SUPPLIER_ADDRESS\",\n",
    "        \"SUPPLIER_CITY\",\n",
    "        \"CITY_LAT\",\n",
    "        \"CITY_LONG\",\n",
    "        \"RATING\"\n",
    "      \n",
    "    \n",
    "    The 'RATING' key value is an integer datatype ranging from 0 stars to 5 stars. Where 0 stars is 'bad' and 5 stars is 'excellent'. Do not include json markdown codeblock syntax in the results for example: ```json ```\n",
    "\n",
    "    {context}\n",
    "\n",
    "    question: {question}\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "PROMPT = PromptTemplate(template = prompt_template, \n",
    "                        input_variables=[\"context\", \"question\"]\n",
    "                       )\n",
    "    \n",
    "chain_type_kwargs = {\"prompt\": PROMPT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Generate more accurate, grounded answers with retrieved context \n",
    "This code snippet integrates various components from the `langchain` library to create a retrieval-based question-answering (QA) system. Here's a breakdown of the key parts and their functionality:\n",
    "\n",
    "- **Retriever Initialization:** The `db.as_retriever` function is used to initialize a retriever object with specific search arguments (`'k':20`), which likely defines the number of search results to consider.\n",
    "\n",
    "- **Prompt Template :** The `PromptTemplate` was defined in the previous step that instructs how to use the context to answer a question. It emphasizes not to fabricate answers if the information is unavailable. The template also outlines the structure for the expected JSON output with various product and supplier details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Find products with a rating of 4 and more.\"\n",
    "retriever = vector_table.as_retriever(search_kwargs={'k':20})\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(llm=llm,\n",
    "                 retriever=retriever, \n",
    "                 chain_type=\"stuff\",\n",
    "                 chain_type_kwargs= chain_type_kwargs)\n",
    "\n",
    "answer = qa.run(question)\n",
    "print(answer)\n",
    "print(\"üíØThis is the end of the demo. Thank you for your attention!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üößOptional Exercise: SAP HANA Cloud multi-modeling with Spatial and Vector engines\n",
    "In this demo, we will explore how to combine the vector embeddings with spatial data within the same SQL environment, which is powerful especially for building intelligent applications. You will learn how to define a table including both vector embeddings and spatial data in **SAP HANA Cloud**. At the end, you will visualize the warehouse locations on a map.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØLearning Objectives\n",
    "By the end of this demo, you will be able to:\n",
    "- Understand the data types: vector embeddings and spatial data. \n",
    "- Define a table for both vector embeddings and spatial data.\n",
    "- Visualize the results on a map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üö®Requirements\n",
    "\n",
    "Please review the following requirements before starting the demo: \n",
    "- Enable the additional feature **Document Store** in your SAP HANA Cloud database\n",
    "- Complete the previous demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Save RAG results to SAP HANA Cloud Document Store (JSON)\n",
    "\n",
    "Create a document collection **GX_RAG_PRODUCTS_DEV** to store the RAG results from the previous step. This script iterates over the list of product dictionaries, converting each one into a JSON string before inserting it into the collection. It then queries the collection to fetch and print all the inserted documents, allowing you to verify the insertion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample dataset of product details\n",
    "import json\n",
    "\n",
    "jdata = json.loads(answer)\n",
    "products = jdata\n",
    "collection_name = \"GX_RAG_PRODUCTS_DEV\"\n",
    "\n",
    "# Create a cursor\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Create a collection (document store)\n",
    "try:\n",
    "    cursor.execute(f\"CREATE COLLECTION {collection_name}\")\n",
    "    print(f\"{collection_name} Created!\")\n",
    "    \n",
    "    # Insert JSON data into the collection\n",
    "    for product in products:\n",
    "        json_str = json.dumps(product)\n",
    "        cursor.execute(f\"INSERT INTO {collection_name} VALUES ('{json_str}')\")\n",
    "\n",
    "except :\n",
    "    print(f\"{collection_name} Recreated!\")\n",
    "    cursor.execute(f\"DROP COLLECTION {collection_name}\")\n",
    "    cursor.execute(f\"CREATE COLLECTION {collection_name}\")\n",
    "\n",
    "    # Insert JSON data into the collection\n",
    "    for product in products:\n",
    "        json_str = json.dumps(product)\n",
    "        cursor.execute(f\"INSERT INTO {collection_name} VALUES ('{json_str}')\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is designed to validate the created collection **GX_RAG_PRODUCTS_DEV** by retrieving supplier information, including their ID, city, and location represented as a geospatial point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = \"GX_RAG_PRODUCTS_DEV\"\n",
    "sql = f\"SELECT SUPPLIER_ID, SUPPLIER_CITY,SUPPLIER_ADDRESS,NEW ST_POINT(TO_DOUBLE(CITY_LONG),TO_DOUBLE(CITY_LAT)) AS SUPPLIER_LOCATION FROM {collection_name}\"\n",
    "\n",
    "cursor.execute(sql)\n",
    "suppliers = cursor.fetchall()\n",
    "\n",
    "for supplier in suppliers:\n",
    "    print(supplier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create a new table including both vector embeddings and spatial data\n",
    "This code snippet is designed to create a new table called **GX_SUPPLIER_LOCATIONS**, specifically for storing supplier location information. Note that **SUPPLIER_LOCATION** is a geospatial point representing the supplier's location, created using the `ST_POINT()` function. \n",
    "\n",
    "This point is constructed from two columns - **CITY_LONG** and **CITY_LAT** - which are converted to double precision numbers (representing longitude and latitude, respectively).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = \"GX_SUPPLIER_LOCATIONS_DEV\"\n",
    "sql = f\"\"\"CREATE TABLE {table_name} AS (\n",
    "               SELECT SUPPLIER_ID,\n",
    "               SUPPLIER_CITY,\n",
    "               NEW ST_POINT(\n",
    "               TO_DOUBLE(CITY_LONG),\n",
    "               TO_DOUBLE(CITY_LAT)) AS SUPPLIER_LOCATION,\n",
    "               SUPPLIER_ADDRESS,\n",
    "               PRODUCT_NAME,\n",
    "               RATING\n",
    "\n",
    "               FROM {collection_name})\"\"\"\n",
    "\n",
    "try:\n",
    "    cursor.execute(sql)\n",
    "    print(f\"{table_name} Created!\")\n",
    "\n",
    "except :\n",
    "    print(f\"{table_name} Recreated!\")\n",
    "    cursor.execute(f\"DROP TABLE {table_name}\")\n",
    "    cursor.execute(sql)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Query new table to retrieve the geospatial data. \n",
    "\n",
    "This code snippet is designed to query SAP HANA Cloud using SQL to retrieve information about suppliers, including their IDs, city names, and geographic locations (latitude and longitude). Here's a breakdown of the code's functionality:\n",
    "\n",
    "The latitude and longitude are extracted using the `ST_Y()` and `ST_X()` functions on the **SUPPLIER_LOCATION** column, which is presumably stored as a geospatial data type in the database.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to fetch the geospatial data\n",
    "table_name = \"GX_SUPPLIER_LOCATIONS_DEV\"\n",
    "sql = f\"\"\"SELECT SUPPLIER_ID,\n",
    "               SUPPLIER_CITY,\n",
    "               SUPPLIER_LOCATION.ST_Y() as latitudes, \n",
    "               SUPPLIER_LOCATION.ST_X() as longitudes,\n",
    "               SUPPLIER_ADDRESS,\n",
    "               PRODUCT_NAME,\n",
    "               RATING \n",
    "            FROM {table_name}\"\"\"\n",
    "\n",
    "cursor.execute(sql)\n",
    "\n",
    "# Fetch all the results\n",
    "points = cursor.fetchall()\n",
    "\n",
    "\n",
    "for point in points:\n",
    "    print(point)\n",
    "\n",
    "# Close the cursor and connection\n",
    "cursor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Visualize supplier warehouse locations on a map \n",
    "\n",
    "The provided code snippet uses the `folium` library in Python to create an interactive map centered around Germany. It initializes a map object centered at the coordinates for Germany (latitude 51.1657, longitude 10.4515) with a zoom level of 6. Then, it iterates over a dataset named `data`, which is expected to contain points of interest. Each point in the dataset includes a supplier ID, city name, latitude, and longitude.\n",
    "\n",
    "For each point, the code creates a popup text that includes the city name and supplier ID. It then creates a marker at the point's latitude and longitude, attaches the popup text to this marker, and adds the marker to the map. The result is an interactive map where each marker represents a point of interest, and clicking on a marker displays a popup with additional information about that point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "\n",
    "data = points\n",
    "\n",
    "# Create a map centered around the average location\n",
    "average_lat = sum([item[2] for item in data]) / len(data)\n",
    "average_lon = sum([item[3] for item in data]) / len(data)\n",
    "map = folium.Map(location=[average_lat, average_lon], zoom_start=7)\n",
    "\n",
    "# Loop through each item in data to create markers\n",
    "for supplier_id, city, lat, lon, address, product, rating in data:\n",
    "    popup_text = f\"Supplier ID: {supplier_id}<br>\"\n",
    "    popup_text += f\"City: {city}<br>\"\n",
    "    popup_text += f\"Address: {address}<br>\"\n",
    "    popup_text += f\"Product: {product}<br>\"\n",
    "    popup_text += f\"Rating: {rating}\"\n",
    "    \n",
    "    # Add a marker to the map\n",
    "    folium.Marker(\n",
    "        [lat, lon],\n",
    "        popup=folium.Popup(popup_text, max_width=300,min_width=300)\n",
    "    ).add_to(map)\n",
    "\n",
    "# Display the map\n",
    "map\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
